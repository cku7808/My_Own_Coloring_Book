{"cells":[{"cell_type":"markdown","metadata":{"id":"5VIGyIus8Vr7"},"source":["Take a look at the [repository](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) for more information"]},{"cell_type":"code","source":["# 원본 제작자 코드를 보고싶다면 위 repository 링크를 통해 확인하시기 바랍니다.\n","# 밑에 코드들은 위 링크를 통해 저희가 사용할 데이터로 정제 했습니다.\n","# 저희는 구글 코랩을 통해 구현 해보았습니다."],"metadata":{"id":"J18D2mspM7Kk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","# 구글 코랩에 마운트 합니다."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TKMbWIJCjOMo","executionInfo":{"status":"ok","timestamp":1687412860050,"user_tz":-540,"elapsed":20580,"user":{"displayName":"이정우","userId":"10083734097573968476"}},"outputId":"622e5b74-8034-47e9-fe06-dd0ecc9f2ee8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Install"],"metadata":{"id":"JD84MV7RaRLo"}},{"cell_type":"code","source":["# 현재 파일경로 체크 하세요.\n","import os\n","current_path = os.getcwd()\n","print(current_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B8Lf6fiYG5l8","executionInfo":{"status":"ok","timestamp":1686926447661,"user_tz":-540,"elapsed":14,"user":{"displayName":"이정우","userId":"10083734097573968476"}},"outputId":"163fe21a-594d-4bcd-8bab-106eae29b2a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive')  # 을 미리해주면 밑에 깃 클론할때 내 드라이브로 불러올 수 있습니다."],"metadata":{"id":"XhkqKX-EaPd7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TRm-USlsHgEV"},"outputs":[],"source":["!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pt3igws3eiVp"},"outputs":[],"source":["import os\n","os.chdir('./pytorch-CycleGAN-and-pix2pix') # 다운 받은 폴더 경로로 변경하고 이 경로에서 파일들을 작업합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z1EySlOXwwoa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686926472020,"user_tz":-540,"elapsed":24366,"user":{"displayName":"이정우","userId":"10083734097573968476"}},"outputId":"cf74efbb-0ce8-498f-f906-006226c8866f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.0.1+cu118)\n","Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.15.2+cu118)\n","Collecting dominate>=2.4.0 (from -r requirements.txt (line 3))\n","  Downloading dominate-2.8.0-py2.py3-none-any.whl (29 kB)\n","Collecting visdom>=0.1.8.8 (from -r requirements.txt (line 4))\n","  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting wandb (from -r requirements.txt (line 5))\n","  Downloading wandb-0.15.4-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->-r requirements.txt (line 1)) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->-r requirements.txt (line 1)) (16.0.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (2.27.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (8.4.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.10.1)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.3.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.16.0)\n","Collecting jsonpatch (from visdom>=0.1.8.8->-r requirements.txt (line 4))\n","  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.5.1)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (8.1.3)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 5))\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 5))\n","  Downloading sentry_sdk-1.25.1-py2.py3-none-any.whl (206 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.7/206.7 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 5))\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (6.0)\n","Collecting pathtools (from wandb->-r requirements.txt (line 5))\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb->-r requirements.txt (line 5))\n","  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (3.20.3)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5))\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->-r requirements.txt (line 1)) (2.1.2)\n","Collecting jsonpointer>=1.9 (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4))\n","  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->-r requirements.txt (line 1)) (1.3.0)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5))\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: visdom, pathtools\n","  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408196 sha256=612954d558565f5385b07b1e5cf669f2d551af82f80eaa40352e3bc43dfc6cdb\n","  Stored in directory: /root/.cache/pip/wheels/42/29/49/5bed207bac4578e4d2c0c5fc0226bfd33a7e2953ea56356855\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=c96192912eb600ce266fc5dc156324682d99c0a9a4673e182fed11590d5cbdae\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built visdom pathtools\n","Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, jsonpointer, dominate, docker-pycreds, jsonpatch, gitdb, visdom, GitPython, wandb\n","Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 dominate-2.8.0 gitdb-4.0.10 jsonpatch-1.32 jsonpointer-2.3 pathtools-0.1.2 sentry-sdk-1.25.1 setproctitle-1.3.2 smmap-5.0.0 visdom-0.2.4 wandb-0.15.4\n"]}],"source":["# PyTorch 및 0.4+ 및 기타 종속 항목(예: torchvision, visdom 및 dominate ) 을 설치합니다 .\n","# Conda 사용자의 경우 .NET을 사용하여 새로운 Conda 환경을 만들 수 있습니다 conda env create -f environment.yml.\n","# Docker 사용자를 위해 미리 빌드된 Docker 이미지와 Dockerfile을 제공합니다. Docker 페이지를 참조하십시오 .\n","\n","# pip 사용자의 경우 다음 명령을 입력하십시오 pip install -r requirements.txt.\n","!pip install -r requirements.txt"]},{"cell_type":"markdown","source":["# Sample Datasets 원작자 데이터\n","\n","Download one of the official datasets with:\n","\n","-   `bash ./datasets/download_cyclegan_dataset.sh [apple2orange, summer2winter_yosemite, horse2zebra, monet2photo, cezanne2photo, ukiyoe2photo, vangogh2photo, maps, cityscapes, facades, iphone2dslr_flower, ae_photos]`\n","\n","Or use your own dataset by creating the appropriate folders and adding in the images.\n","\n","-   Create a dataset folder under `/dataset` for your dataset.\n","-   Create subfolders `testA`, `testB`, `trainA`, and `trainB` under your dataset's folder. Place any images you want to transform from a to b (cat2dog) in the `testA` folder, images you want to transform from b to a (dog2cat) in the `testB` folder, and do the same for the `trainA` and `trainB` folders."],"metadata":{"id":"6MSRR0OWg7xL"}},{"cell_type":"code","source":["!bash ./datasets/download_cyclegan_dataset.sh monet2photo  # 원작자 monet 화풍 데이터 다운로드"],"metadata":{"id":"V_S3yrHgg9hs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Pretrained models\n","Download one of the official pretrained models with:\n","\n","bash ./scripts/download_cyclegan_model.sh [apple2orange, orange2apple, summer2winter_yosemite, winter2summer_yosemite, horse2zebra, zebra2horse, monet2photo, style_monet, style_cezanne, style_ukiyoe, style_vangogh, sat2map, map2sat, cityscapes_photo2label, cityscapes_label2photo, facades_photo2label, facades_label2photo, iphone2dslr_flower]\n","Or add your own pretrained model to ./checkpoints/{NAME}_pretrained/latest_net_G.pt"],"metadata":{"id":"ZXCnPTYehA52"}},{"cell_type":"code","source":["!bash ./scripts/download_cyclegan_model.sh monet2photo  # 원작자 monet 화풍 모델 다운로드"],"metadata":{"id":"nNDElu0mhBDp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 우리가 사용할 데이터셋 불러오고 나눠서 저장"],"metadata":{"id":"rN9X1bmJRs54"}},{"cell_type":"code","source":["!unzip -qq \"./DL 3조/사진/archive.zip\" -d \"./DL 3조/CycleGan결과/A\" # 저희는 현재 경로에서 DL 3조 공유폴더를 추가해서 진행했습니다.\n","                                                                    # https://www.kaggle.com/datasets/arnaud58/landscape-pictures 위 링크에서 데이터를 다운 받고 압축을 푸는 과정입니다."],"metadata":{"id":"ay85wJv-Rfnm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import random\n","import shutil\n","\n","def split_folder_files(folder_path, output_folder):\n","    # 폴더 내 모든 파일 가져오기\n","    files = os.listdir(folder_path)\n","    random.shuffle(files)\n","\n","    # 파일 개수\n","    num_files = len(files)\n","\n","    # 반으로 나누기\n","    num_files_half = num_files // 2\n","\n","    # 첫 번째 반 저장\n","    first_half = files[:num_files_half]\n","    first_half_output_folder = os.path.join(output_folder, 'first_half')\n","    os.makedirs(first_half_output_folder, exist_ok=True)\n","    for file in first_half:\n","        file_path = os.path.join(folder_path, file)\n","        output_file_path = os.path.join(first_half_output_folder, file)\n","        shutil.move(file_path, output_file_path)\n","\n","    # 두 번째 반 저장\n","    second_half = files[num_files_half:]\n","    second_half_output_folder = os.path.join(output_folder, 'second_half')\n","    os.makedirs(second_half_output_folder, exist_ok=True)\n","    for file in second_half:\n","        file_path = os.path.join(folder_path, file)\n","        output_file_path = os.path.join(second_half_output_folder, file)\n","        shutil.move(file_path, output_file_path)\n","\n","    print('파일 분할이 완료되었습니다.')\n","\n","# 예시 사용법\n","folder_path = '/content/drive/MyDrive/pytorch-CycleGAN-and-pix2pix/DL 3조/CycleGan결과/AA'\n","output_folder = '/content/drive/MyDrive/pytorch-CycleGAN-and-pix2pix/DL 3조/CycleGan결과'\n","split_folder_files(folder_path, output_folder)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CguGNz6oIxnI","executionInfo":{"status":"ok","timestamp":1686733358042,"user_tz":-540,"elapsed":32225,"user":{"displayName":"이정우","userId":"10083734097573968476"}},"outputId":"ebe95db7-b536-4a9f-c7b3-60e785ddfc7b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["파일 분할이 완료되었습니다.\n"]}]},{"cell_type":"code","source":["#위 코드를 통해 trainA와 testA 파일을 만들었습니다.\n","#위 파일들과 같은 경로에 자신이 원하는 화풍들이 담긴 이미지들을 trainB 라는 폴더를 만들어 저장해줍니다."],"metadata":{"id":"1p87bQrIQnbb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n"],"metadata":{"id":"SpBRV3rWgCXs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training 원작자 설명\n","\n","-   `python train.py --dataroot ./datasets/horse2zebra --name horse2zebra --model cycle_gan`\n","\n","Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. I've found that a batch size of 16 fits onto 4 V100s and can finish training an epoch in ~90s.\n","\n","Once your model has trained, copy over the last checkpoint to a format that the testing model can automatically detect:\n","\n","Use `cp ./checkpoints/horse2zebra/latest_net_G_A.pth ./checkpoints/horse2zebra/latest_net_G.pth` if you want to transform images from class A to class B and `cp ./checkpoints/horse2zebra/latest_net_G_B.pth ./checkpoints/horse2zebra/latest_net_G.pth` if you want to transform images from class B to class A.\n","\n","\n","```\n","\n"],"metadata":{"id":"mWsNn_TjgU4f"}},{"cell_type":"code","source":["# 원작자 훈련 코드\n","!python train.py --dataroot ./datasets/monet2photo --name monet2photo --model cycle_gan --display_id -1"],"metadata":{"id":"0_oSA-J7fiS-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 원작자 코드에서 배치사이즈 훈련 에코프 수 등을 조정할 수 있고 특정 epoch마다(보통5epoch) 체크포인트에 저장 되기 때문에\n","# 저장된 체크포인트를  --continue_train 을 통해 훈련을 재개할 수 있습니다.\n","# 원하는 훈련 모델 결과 경로와 체크포인트를 저장한 이름도 마음대로 지정해줘도 됩니다."],"metadata":{"id":"JORW9rsKPvCj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 야수파 훈련 25"],"metadata":{"id":"6c-VSR8TTHql"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train.py --dataroot \"./DL 3조/CycleGan결과\" --name 야수파 --model cycle_gan --display_id -1 --batch_size 16  --n_epochs 25 --n_epochs_decay 0 --gpu_ids 0"],"metadata":{"id":"36Q5kVHC22Bk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 야수파 훈련25+25"],"metadata":{"id":"e1iDoqWzDzFh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train.py --dataroot \"./DL 3조/CycleGan결과\" --name 야수파 --model cycle_gan --display_id -1 --batch_size 16  --n_epochs 25 --n_epochs_decay 0 --gpu_ids 0 --continue_train"],"metadata":{"id":"hmYCqB7n22D3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 야수파 25+25+25"],"metadata":{"id":"nHfGlTm-22F1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train.py --dataroot \"./DL 3조/CycleGan결과\" --name 야수파 --model cycle_gan --display_id -1--batch_size 16  --n_epochs 25 --n_epochs_decay 0 --gpu_ids 0 --continue_train"],"metadata":{"id":"X_TamexrTHtn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","\n","\n"],"metadata":{"id":"6W5ig3x7ej1t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 야수파 -> 가장 최근 체크포인트를 가져와 test할 가중치에 저장해줍니다.\n","!cp ./checkpoints/야수파/latest_net_G_A.pth ./checkpoints/야수파/latest_net_G.pth"],"metadata":{"id":"gGHJy8Wz2-Cf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 원하는 체크포인트를 가져와서 latest_net_G.pth에 저장하면 그 가중치로 test 할 수 있습니다."],"metadata":{"id":"zhEKxHJTJyHM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp ./checkpoints/야수파/5_net_G_A.pth ./checkpoints/야수파/latest_net_G.pth"],"metadata":{"id":"7Jx1kwbBJyKK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n"],"metadata":{"id":"iDNIQDkMfClK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9UkcaFZiyASl"},"source":["# Testing 원작자 설명\n","\n","-   `python test.py --dataroot datasets/horse2zebra/testA --name horse2zebra_pretrained --model test --no_dropout`\n","\n","Change the `--dataroot` and `--name` to be consistent with your trained model's configuration.\n","\n","> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n","> The option --model test is used for generating results of CycleGAN only for one side. This option will automatically set --dataset_mode single, which only loads the images from one set. On the contrary, using --model cycle_gan requires loading and generating results in both directions, which is sometimes unnecessary. The results will be saved at ./results/. Use --results_dir {directory_path_to_save_result} to specify the results directory.\n","\n","> For your own experiments, you might want to specify --netG, --norm, --no_dropout to match the generator architecture of the trained model."]},{"cell_type":"code","source":["# 야수파 25"],"metadata":{"id":"PsTPoLyl2gwy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python test.py --dataroot  \"./DL 3조/CycleGan결과/testA\" --name 야수파 --model test --no_dropout --results_dir \"./DL 3조/CycleGan결과/야수파결과/1\""],"metadata":{"id":"VsE4oWcX3Jt6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 야수파 25+25"],"metadata":{"id":"eWbz9b443JwL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python test.py --dataroot  \"./DL 3조/CycleGan결과/testA\" --name 야수파 --model test --no_dropout --results_dir \"./DL 3조/CycleGan결과/야수파결과/2\""],"metadata":{"id":"HVw13FAED85Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 야수파 25+25+25"],"metadata":{"id":"eHTVSQUzQHt5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python test.py --dataroot  \"./DL 3조/CycleGan결과/testA\" --name 야수파 --model test --no_dropout --results_dir \"./DL 3조/CycleGan결과/야수파결과/3\" --num_test 2161"],"metadata":{"id":"Q8EpP3z8D87k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 만들어진 train 모델을 test하고 이름과 결과 파일을 저장할 경로를 지정해줍니다.\n","# 이후 결과 파일 경로를 확인하시면 화풍변환된 이미지들이 FAKE와 REAL 두가지 형태로 비교할 수 있게 저장되어 있을 겁니다.\n","# test 결과는 기본 default가 50장이며 --num_test 2161 지정해주면 모든 test 사진들의 결과를 볼 수 있습니다."],"metadata":{"id":"DfZJORocRgsp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 감사합니다."],"metadata":{"id":"OGlS2OEHRgws"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1Uk-B3w_Hxlc-iszA7QrtQIZGfxE-5SA5","timestamp":1687494122289},{"file_id":"https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/CycleGAN.ipynb","timestamp":1686124236501}],"gpuType":"A100"},"environment":{"name":"tf2-gpu.2-3.m74","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":0}