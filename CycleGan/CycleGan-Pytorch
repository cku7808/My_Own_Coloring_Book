{"cells":[{"cell_type":"markdown","metadata":{"id":"5VIGyIus8Vr7"},"source":["Take a look at the [repository](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) for more information"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TKMbWIJCjOMo","executionInfo":{"status":"ok","timestamp":1687412860050,"user_tz":-540,"elapsed":20580,"user":{"displayName":"이정우","userId":"10083734097573968476"}},"outputId":"622e5b74-8034-47e9-fe06-dd0ecc9f2ee8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Install"],"metadata":{"id":"JD84MV7RaRLo"}},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B8Lf6fiYG5l8","executionInfo":{"status":"ok","timestamp":1686926447661,"user_tz":-540,"elapsed":14,"user":{"displayName":"이정우","userId":"10083734097573968476"}},"outputId":"163fe21a-594d-4bcd-8bab-106eae29b2a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive')"],"metadata":{"id":"XhkqKX-EaPd7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TRm-USlsHgEV"},"outputs":[],"source":["!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pt3igws3eiVp"},"outputs":[],"source":["import os\n","os.chdir('./pytorch-CycleGAN-and-pix2pix')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z1EySlOXwwoa"},"outputs":[],"source":["!pip install -r requirements.txt"]},{"cell_type":"markdown","source":["# Sample Datasets\n","\n","Download one of the official datasets with:\n","\n","-   `bash ./datasets/download_cyclegan_dataset.sh [apple2orange, summer2winter_yosemite, horse2zebra, monet2photo, cezanne2photo, ukiyoe2photo, vangogh2photo, maps, cityscapes, facades, iphone2dslr_flower, ae_photos]`\n","\n","Or use your own dataset by creating the appropriate folders and adding in the images.\n","\n","-   Create a dataset folder under `/dataset` for your dataset.\n","-   Create subfolders `testA`, `testB`, `trainA`, and `trainB` under your dataset's folder. Place any images you want to transform from a to b (cat2dog) in the `testA` folder, images you want to transform from b to a (dog2cat) in the `testB` folder, and do the same for the `trainA` and `trainB` folders."],"metadata":{"id":"6MSRR0OWg7xL"}},{"cell_type":"code","source":["!bash ./datasets/download_cyclegan_dataset.sh monet2photo"],"metadata":{"id":"V_S3yrHgg9hs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Pretrained models\n","Download one of the official pretrained models with:\n","\n","bash ./scripts/download_cyclegan_model.sh [apple2orange, orange2apple, summer2winter_yosemite, winter2summer_yosemite, horse2zebra, zebra2horse, monet2photo, style_monet, style_cezanne, style_ukiyoe, style_vangogh, sat2map, map2sat, cityscapes_photo2label, cityscapes_label2photo, facades_photo2label, facades_label2photo, iphone2dslr_flower]\n","Or add your own pretrained model to ./checkpoints/{NAME}_pretrained/latest_net_G.pt"],"metadata":{"id":"ZXCnPTYehA52"}},{"cell_type":"code","source":["!bash ./scripts/download_cyclegan_model.sh monet2photo"],"metadata":{"id":"nNDElu0mhBDp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 자신의 데이터셋 불러오고 나누고 저장하기"],"metadata":{"id":"rN9X1bmJRs54"}},{"cell_type":"code","source":["!unzip -qq \"./DL 3조/사진/archive.zip\" -d \"./DL 3조/CycleGan결과/A\"  # 자신이 원하는 파일 압축 해제 하세요."],"metadata":{"id":"ay85wJv-Rfnm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import random\n","import shutil\n","\n","def split_folder_files(folder_path, output_folder):\n","    # 폴더 내 모든 파일 가져오기\n","    files = os.listdir(folder_path)\n","    random.shuffle(files)\n","\n","    # 파일 개수\n","    num_files = len(files)\n","\n","    # 반으로 나누기\n","    num_files_half = num_files // 2\n","\n","    # 첫 번째 반 저장 (trainA)\n","    first_half = files[:num_files_half]\n","    first_half_output_folder = os.path.join(output_folder, 'trainA')\n","    os.makedirs(first_half_output_folder, exist_ok=True)\n","    for file in first_half:\n","        file_path = os.path.join(folder_path, file)\n","        output_file_path = os.path.join(first_half_output_folder, file)\n","        shutil.move(file_path, output_file_path)\n","\n","    # 두 번째 반 저장 (testB)\n","    second_half = files[num_files_half:]\n","    second_half_output_folder = os.path.join(output_folder, 'testB')\n","    os.makedirs(second_half_output_folder, exist_ok=True)\n","    for file in second_half:\n","        file_path = os.path.join(folder_path, file)\n","        output_file_path = os.path.join(second_half_output_folder, file)\n","        shutil.move(file_path, output_file_path)\n","\n","    print('파일 분할이 완료되었습니다.')\n","\n","\n","# 예시 사용법\n","folder_path = '/content/drive/MyDrive/pytorch-CycleGAN-and-pix2pix/DL 3조/CycleGan결과/A'\n","output_folder = '/content/drive/MyDrive/pytorch-CycleGAN-and-pix2pix/DL 3조/CycleGan결과'\n","split_folder_files(folder_path, output_folder)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CguGNz6oIxnI","executionInfo":{"status":"ok","timestamp":1686733358042,"user_tz":-540,"elapsed":32225,"user":{"displayName":"이정우","userId":"10083734097573968476"}},"outputId":"ebe95db7-b536-4a9f-c7b3-60e785ddfc7b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["파일 분할이 완료되었습니다.\n"]}]},{"cell_type":"code","source":["\n","\n"],"metadata":{"id":"ZbxXbO9fkaNS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training\n","\n","-   `python train.py --dataroot ./datasets/horse2zebra --name horse2zebra --model cycle_gan`\n","\n","Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. I've found that a batch size of 16 fits onto 4 V100s and can finish training an epoch in ~90s.\n","\n","Once your model has trained, copy over the last checkpoint to a format that the testing model can automatically detect:\n","\n","Use `cp ./checkpoints/horse2zebra/latest_net_G_A.pth ./checkpoints/horse2zebra/latest_net_G.pth` if you want to transform images from class A to class B and `cp ./checkpoints/horse2zebra/latest_net_G_B.pth ./checkpoints/horse2zebra/latest_net_G.pth` if you want to transform images from class B to class A.\n","\n","\n","```\n","\n"],"metadata":{"id":"mWsNn_TjgU4f"}},{"cell_type":"code","source":["# 원본 코드\n","!python train.py --dataroot ./datasets/monet2photo --name monet2photo --model cycle_gan --display_id -1"],"metadata":{"id":"0_oSA-J7fiS-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 야수파 훈련 25"],"metadata":{"id":"6c-VSR8TTHql"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train.py --dataroot \"./DL 3조/CycleGan결과\" --name 야수파 --model cycle_gan --display_id -1--batch_size 16  --n_epochs 25 --n_epochs_decay 0 --gpu_ids 0"],"metadata":{"id":"36Q5kVHC22Bk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 야수파 훈련25+25"],"metadata":{"id":"e1iDoqWzDzFh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train.py --dataroot \"./DL 3조/CycleGan결과\" --name 야수파 --model cycle_gan --display_id -1 --batch_size 16  --n_epochs 25 --n_epochs_decay 0 --gpu_ids 0 --continue_train"],"metadata":{"id":"hmYCqB7n22D3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 야수파 25+25+25"],"metadata":{"id":"nHfGlTm-22F1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train.py --dataroot \"./DL 3조/CycleGan결과\" --name 야수파 --model cycle_gan --display_id -1 --batch_size 16  --n_epochs 25 --n_epochs_decay 0 --gpu_ids 0 --continue_train"],"metadata":{"id":"X_TamexrTHtn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","\n","\n"],"metadata":{"id":"6W5ig3x7ej1t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 야수파\n","!cp ./checkpoints/야수파/latest_net_G_A.pth ./checkpoints/야수파/latest_net_G.pth"],"metadata":{"id":"gGHJy8Wz2-Cf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 야수파 원하는거 복사"],"metadata":{"id":"zhEKxHJTJyHM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp ./checkpoints/야수파/5_net_G_A.pth ./checkpoints/야수파/latest_net_G.pth"],"metadata":{"id":"7Jx1kwbBJyKK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n"],"metadata":{"id":"iDNIQDkMfClK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9UkcaFZiyASl"},"source":["# Testing\n","\n","-   `python test.py --dataroot datasets/horse2zebra/testA --name horse2zebra_pretrained --model test --no_dropout`\n","\n","Change the `--dataroot` and `--name` to be consistent with your trained model's configuration.\n","\n","> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n","> The option --model test is used for generating results of CycleGAN only for one side. This option will automatically set --dataset_mode single, which only loads the images from one set. On the contrary, using --model cycle_gan requires loading and generating results in both directions, which is sometimes unnecessary. The results will be saved at ./results/. Use --results_dir {directory_path_to_save_result} to specify the results directory.\n","\n","> For your own experiments, you might want to specify --netG, --norm, --no_dropout to match the generator architecture of the trained model."]},{"cell_type":"code","source":["# 야수파 25"],"metadata":{"id":"PsTPoLyl2gwy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python test.py --dataroot  \"./DL 3조/CycleGan결과/testA\" --name 야수파 --model test --no_dropout --results_dir \"./DL 3조/CycleGan결과/야수파결과/1\""],"metadata":{"id":"VsE4oWcX3Jt6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 야수파 25+25"],"metadata":{"id":"eWbz9b443JwL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python test.py --dataroot  \"./DL 3조/CycleGan결과/testA\" --name 야수파 --model test --no_dropout --results_dir \"./DL 3조/CycleGan결과/야수파결과/2\""],"metadata":{"id":"HVw13FAED85Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 야수파 25+25+25"],"metadata":{"id":"eHTVSQUzQHt5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python test.py --dataroot  \"./DL 3조/CycleGan결과/testA\" --name 야수파 --model test --no_dropout --results_dir \"./DL 3조/CycleGan결과/야수파결과/3\" --num_test 2160"],"metadata":{"id":"Q8EpP3z8D87k"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1Uk-B3w_Hxlc-iszA7QrtQIZGfxE-5SA5","timestamp":1687494122289},{"file_id":"https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/CycleGAN.ipynb","timestamp":1686124236501}],"gpuType":"A100"},"environment":{"name":"tf2-gpu.2-3.m74","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":0}